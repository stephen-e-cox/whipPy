{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGixmes3K1QQsufWgKcrfP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephen-e-cox/whipPy/blob/main/whipPy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1099,
      "metadata": {
        "id": "g2Av0wUn6vgq"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import re\n",
        "from itertools import groupby\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import gspread\n",
        "import gspread_dataframe as gd\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Edit this section for each new import\n",
        "\n",
        "racedate = datetime.date(2023, 2, 5) ## date in year-month-day format\n",
        "racedist = 10 ## distance in one of the below units (for named distances like marathon, use 1)\n",
        "racedist_units = \"km\" ## miles, km, m, marathon, half marathon\n",
        "racefile_name = \"2023_NYRR_Manhattan_10K\"\n",
        "pointsrace = False"
      ],
      "metadata": {
        "id": "6GdghgwgcsUh"
      },
      "execution_count": 1100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This is the master spreadsheet\n",
        "wb = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1n_xmaQuNmj3JBfOXJEN8c4HZAOUPOjtPAM-fY4h4K54/edit#gid=0\")\n",
        "\n",
        "## This is the spreadsheet and worksheet containing current team time standards\n",
        "stds = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1G7a3kSUUD1TZRWZbeACTwQxQfW4yCdJqC5qytQ-EgdM/edit#gid=0\")\n",
        "qual_stds = stds.worksheet('2022_standards').get_all_values()\n",
        "\n",
        "## This is the spreadsheet and worksheet containing current NYRR corral time standards\n",
        "stds = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1cfpRUCy7sMbxNH6ITANn0L-mEE5AUHp98auuHGO3SC4/edit#gid=0\")\n",
        "corral_stds = stds.worksheet('Current').get_all_values()\n",
        "\n",
        "## This is the spreadsheet and worksheet containing NYRR best pace multipliers\n",
        "stds = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1Z482pFFoDRFikEhVmjCcHllaEvO6Otpauak94AQbAYk/edit#gid=0\")\n",
        "best_paces = stds.worksheet('Current').get_all_values()\n",
        "\n",
        "## This is the new race file to read. Drop it in the temporary files list in Colab. It will not be saved.\n",
        "racefile = open(racefile_name + \".txt\")\n",
        "\n",
        "## This creates a new worksheet with the name of the racefile. If it already\n",
        "## exists, it will be deleted!\n",
        "try:\n",
        "  ws = wb.add_worksheet(racefile_name, rows=1, cols=1)\n",
        "except:\n",
        "  ws = wb.worksheet(racefile_name)\n",
        "  wb.del_worksheet(ws)\n",
        "  ws = wb.add_worksheet(racefile_name, rows=1, cols=1)\n",
        "\n",
        "## This creates a single archive of the summary spreadsheet, and deletes any\n",
        "## existing one. This is just a light backup solution in case you screw up an\n",
        "## import\n",
        "sum_worksheet = wb.worksheet(\"Summary\")\n",
        "try:\n",
        "  wb.duplicate_sheet(sum_worksheet.id, new_sheet_name=\"Summary_archive\")\n",
        "except:\n",
        "  sum_arch_worksheet = wb.worksheet(\"Summary_archive\")\n",
        "  wb.del_worksheet(sum_arch_worksheet)\n",
        "  wb.duplicate_sheet(sum_worksheet.id, new_sheet_name=\"Summary_archive\")"
      ],
      "metadata": {
        "id": "DfBzH4z77I_y"
      },
      "execution_count": 1101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Process the race results into a friendly format\n",
        "\n",
        "## Split it up by line first\n",
        "racefile.seek(0)\n",
        "data = racefile.read().split('\\n')\n",
        "\n",
        "## The format we get from NYRR page copy/paste is eight lines per entry\n",
        "chunks = [data[x:x+8] for x in range(0, len(data), 8)]\n",
        "\n",
        "racedata = pd.DataFrame(chunks, columns=[\"Name\", \"AgeLocBib\", \"Text1\", \"Time\", \"Text2\", \"Pace\", \"Text3\", \"Place\"])\n",
        "\n",
        "## Split Age/Location/Bib line\n",
        "racedata[[\"Age\", \"LocBib\"]] = racedata[\"AgeLocBib\"].str.split(n=1, expand=True)\n",
        "racedata[[\"Location\", \"Text4\", \"Bib\"]] = racedata[\"LocBib\"].str.rsplit(n=2, expand=True)\n",
        "racedata['Gender'] = racedata['Age'].str[0]\n",
        "racedata['Age'] = racedata['Age'].str[1:]\n",
        "\n",
        "## We don't need labels like \"Time\" from the text file. We are also not using these\n",
        "## to reshape because there is no \"Name\" or \"Age/Location\" label\n",
        "racedata.drop(columns=[\"AgeLocBib\", \"LocBib\", \"Text1\", \"Text2\", \"Text3\", \"Text4\"], inplace=True)\n",
        "\n",
        "## Format numeric columns. There is probably a more elegant way to do this but it\n",
        "## is tough to convince python/Pandas to treat time-formatted columns\n",
        "## as length of time rather than timestamp or elapsed time since X\n",
        "Time_formatted = pd.to_datetime(racedata[\"Time\"], format = '%H:%M:%S')\n",
        "Pace_formatted = pd.to_datetime(racedata[\"Pace\"], format = '%M:%S')\n",
        "racedata['Time_s'] = ((Time_formatted - Time_formatted.dt.normalize()) / pd.Timedelta('1 second')).astype(int)\n",
        "racedata['Pace_s'] = ((Pace_formatted - Pace_formatted.dt.normalize()) / pd.Timedelta('1 second')).astype(int)\n",
        "racedata[\"Place\"] = racedata[\"Place\"].map(lambda s: s.replace(',',''))\n",
        "racedata[\"Place\"] = pd.to_numeric(racedata[\"Place\"])\n",
        "racedata[\"Age\"] = pd.to_numeric(racedata[\"Age\"])"
      ],
      "metadata": {
        "id": "qkRO-7pxOhCq"
      },
      "execution_count": 1102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load the NYRR best pace data\n",
        "bp_df = pd.DataFrame(best_paces)\n",
        "bp_df.columns = bp_df.iloc[0]\n",
        "bp_df = bp_df.iloc[1:]\n",
        "\n",
        "bp_df[\"Distance\"] = pd.to_numeric(bp_df[\"Distance\"])\n",
        "bp_df[\"Multiplier\"] = pd.to_numeric(bp_df[\"Multiplier\"])\n",
        "\n",
        "try:\n",
        "  bp_mult = bp_df[(bp_df[\"Distance\"] == racedist) & (bp_df[\"Units\"] == racedist_units)][\"Multiplier\"].values[0]\n",
        "except IndexError:\n",
        "  bp_mult = np.nan"
      ],
      "metadata": {
        "id": "0CCnpCtnIvnp"
      },
      "execution_count": 1103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load corral data and calculate NYRR best paces and corrals\n",
        "corral_df = pd.DataFrame(corral_stds)\n",
        "corral_df.columns = corral_df.iloc[0]\n",
        "corral_df = corral_df.iloc[1:]\n",
        "\n",
        "corral_df[\"Hours\"] = pd.to_numeric(corral_df[\"Hours\"])\n",
        "corral_df[\"Minutes\"] = pd.to_numeric(corral_df[\"Minutes\"])\n",
        "corral_df[\"Seconds\"] = pd.to_numeric(corral_df[\"Seconds\"])\n",
        "corral_df[\"high_Seconds\"] = corral_df[\"Seconds\"] + corral_df[\"Minutes\"]*60 + corral_df[\"Hours\"]*3600\n",
        "corral_df[\"low_Seconds\"] = corral_df[\"high_Seconds\"].shift(1, fill_value=0)\n",
        "\n",
        "racedata = racedata.drop(['Corral'], axis=1, errors='ignore')\n",
        "racedata[\"BestPace_s\"] = racedata[\"Time_s\"]*bp_mult/6.21371192237\n",
        "racedata[\"BestPace_s\"] = racedata['BestPace_s'].round(decimals = 0)\n",
        "\n",
        "if np.isnan(bp_mult):\n",
        "  racedata[\"BestPace\"] = racedata[\"BestPace_s\"]\n",
        "  racedata['Corral'] = \"N/A\"\n",
        "else:\n",
        "  racedata[\"BestPace\"] = pd.to_datetime((racedata['BestPace_s']).astype('int'), unit='s')\n",
        "  racedata[\"BestPace\"] = racedata[\"BestPace\"].dt.strftime(\"%M:%S\")\n",
        "\n",
        "  mrg = racedata.assign(key=1).merge(corral_df.assign(key=1), on='key')\\\n",
        "                        .drop(columns='key')\n",
        "\n",
        "  racedata = mrg[mrg['BestPace_s'].between(mrg['low_Seconds'], mrg['high_Seconds'])]\\\n",
        "                      .drop(columns=['low_Seconds', 'high_Seconds', 'Hours',\\\n",
        "                                      'Minutes', 'Seconds'])\\\n",
        "                      .reset_index(drop=True)\n",
        "\n",
        "  conditions = [\\\n",
        "      (racedata['Corral'] == 'AA_M') & (racedata['Gender'] == 'M'),\n",
        "      (racedata['Corral'] == 'AA_WX') & (racedata['Gender'] == 'M'),\n",
        "      (racedata['Corral'] == 'AA_M') & (racedata['Gender'] == 'W'),\n",
        "      (racedata['Corral'] == 'AA_M') & (racedata['Gender'] == 'X'),\n",
        "      (racedata['Corral'] == 'AA_WX') & (racedata['Gender'] == 'W'),\n",
        "      (racedata['Corral'] == 'AA_WX') & (racedata['Gender'] == 'X')]\n",
        "\n",
        "  values = ['AA', 'A', 'AA', 'AA', 'AA', 'AA']\n",
        "\n",
        "  racedata['Corral'] = np.select(conditions, values, default=racedata['Corral'])"
      ],
      "metadata": {
        "id": "BxJotYMpLhBl"
      },
      "execution_count": 1104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load the qualifying time\n",
        "stds_df = pd.DataFrame(qual_stds)\n",
        "stds_df.columns = stds_df.iloc[0]\n",
        "stds_df = stds_df.iloc[1:]\n",
        "\n",
        "stds_df[\"Distance\"] = pd.to_numeric(stds_df[\"Distance\"])\n",
        "stds_df[\"Hours\"] = pd.to_numeric(stds_df[\"Hours\"])\n",
        "stds_df[\"Minutes\"] = pd.to_numeric(stds_df[\"Minutes\"])\n",
        "stds_df[\"Seconds\"] = pd.to_numeric(stds_df[\"Seconds\"])\n",
        "\n",
        "stds_df['Time_standard_s'] = stds_df['Hours']*3600 + stds_df['Minutes']*60 + stds_df['Seconds']\n",
        "\n",
        "# try: \n",
        "dist_filter = stds_df['Distance'] == racedist\n",
        "unit_filter = stds_df['Units'] == racedist_units\n",
        "\n",
        "women_filter = stds_df['Gender'] == \"W\"\n",
        "men_filter = stds_df['Gender'] == \"M\"\n",
        "nonbinary_filter = stds_df['Gender'] == \"X\"\n",
        "\n",
        "## If the standard is not present, it will be set to zero, which will result in \n",
        "## no runners achieving the standard, and an empty qualifying table\n",
        "\n",
        "try:\n",
        "  std_women = stds_df.loc[dist_filter & unit_filter & women_filter]['Time_standard_s'].item()\n",
        "except:\n",
        "  std_women = 0\n",
        "\n",
        "try:\n",
        "  std_men = stds_df.loc[dist_filter & unit_filter & men_filter]['Time_standard_s'].item()\n",
        "except:\n",
        "  std_men = 0\n",
        "\n",
        "try:\n",
        "  std_nonbinary = stds_df.loc[dist_filter & unit_filter & nonbinary_filter]['Time_standard_s'].item()\n",
        "except:\n",
        "  std_nonbinary = 0"
      ],
      "metadata": {
        "id": "i8Efv63Wyh_b"
      },
      "execution_count": 1105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Search for qualifying times and top performances\n",
        "racedata_women = racedata.query(\"Gender == 'W'\")\n",
        "racedata_men = racedata.query(\"Gender == 'M'\")\n",
        "racedata_nonbinary = racedata.query(\"Gender == 'X'\")\n",
        "\n",
        "top_women = racedata_women.nsmallest(10, columns=\"Time_s\")\n",
        "top_men = racedata_men.nsmallest(10, columns=\"Time_s\")\n",
        "top_nonbinary = racedata_nonbinary.nsmallest(10, columns=\"Time_s\")\n",
        "\n",
        "qualifying_women = racedata_women.query(\"Time_s <= {}\".format(std_women))\n",
        "qualifying_men = racedata_men.query(\"Time_s <= {}\".format(std_men))\n",
        "qualifying_nonbinary = racedata_nonbinary.query(\"Time_s <= {}\".format(std_nonbinary))"
      ],
      "metadata": {
        "id": "edB71TwBclM-"
      },
      "execution_count": 1106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Write the Google sheet for this race\n",
        "\n",
        "ws = wb.worksheet(racefile_name)\n",
        "ws.add_rows(2)\n",
        "ws.update_cell(ws.row_count+2, 1, 'Qualifying Women')\n",
        "\n",
        "if qualifying_women.shape[0] > 0:\n",
        "  ws = wb.worksheet(racefile_name)\n",
        "  ws.add_rows(qualifying_women.shape[0])\n",
        "  gd.set_with_dataframe(worksheet=ws,dataframe=qualifying_women,include_index=False,include_column_header=True,row=ws.row_count+1,resize=False)\n",
        "\n",
        "ws = wb.worksheet(racefile_name)\n",
        "ws.add_rows(2)\n",
        "ws.update_cell(ws.row_count+2, 1, 'Qualifying Men')\n",
        "\n",
        "if qualifying_men.shape[0] > 0:\n",
        "  ws = wb.worksheet(racefile_name)\n",
        "  ws.add_rows(qualifying_men.shape[0])\n",
        "  gd.set_with_dataframe(worksheet=ws,dataframe=qualifying_men,include_index=False,include_column_header=True,row=ws.row_count+1,resize=False)\n",
        "\n",
        "ws = wb.worksheet(racefile_name)\n",
        "ws.add_rows(2)\n",
        "ws.update_cell(ws.row_count+2, 1, 'Qualifying Nonbinary')\n",
        "\n",
        "if qualifying_nonbinary.shape[0] > 0:\n",
        "  ws = wb.worksheet(racefile_name)\n",
        "  ws.add_rows(qualifying_nonbinary.shape[0])\n",
        "  gd.set_with_dataframe(worksheet=ws,dataframe=qualifying_nonbinary,include_index=False,include_column_header=True,row=ws.row_count+1,resize=False)\n",
        "\n",
        "ws = wb.worksheet(racefile_name)\n",
        "ws.add_rows(2)\n",
        "ws.update_cell(ws.row_count+2, 1, 'Top Women')\n",
        "\n",
        "if top_women.shape[0] > 0:\n",
        "  ws = wb.worksheet(racefile_name)\n",
        "  ws.add_rows(top_women.shape[0])\n",
        "  gd.set_with_dataframe(worksheet=ws,dataframe=top_women,include_index=False,include_column_header=True,row=ws.row_count+1,resize=False)\n",
        "\n",
        "ws = wb.worksheet(racefile_name)\n",
        "ws.add_rows(2)\n",
        "ws.update_cell(ws.row_count+2, 1, 'Top Men')\n",
        "\n",
        "if top_men.shape[0] > 0:\n",
        "  ws = wb.worksheet(racefile_name)\n",
        "  ws.add_rows(top_men.shape[0])\n",
        "  gd.set_with_dataframe(worksheet=ws,dataframe=top_men,include_index=False,include_column_header=True,row=ws.row_count+1,resize=False)\n",
        "\n",
        "ws = wb.worksheet(racefile_name)\n",
        "ws.add_rows(2)\n",
        "ws.update_cell(ws.row_count+2, 1, 'Top Nonbinary')\n",
        "\n",
        "if top_nonbinary.shape[0] > 0:\n",
        "  ws = wb.worksheet(racefile_name)\n",
        "  ws.add_rows(top_nonbinary.shape[0])\n",
        "  gd.set_with_dataframe(worksheet=ws,dataframe=top_nonbinary,include_index=False,include_column_header=True,row=ws.row_count+1,resize=False)\n",
        "\n",
        "ws = wb.worksheet(racefile_name)\n",
        "ws.add_rows(2)\n",
        "ws.update_cell(ws.row_count+2, 1, 'All Team Results')\n",
        "\n",
        "ws = wb.worksheet(racefile_name)\n",
        "ws.add_rows(racedata.shape[0])\n",
        "gd.set_with_dataframe(worksheet=ws,dataframe=racedata,include_index=False,include_column_header=True,row=ws.row_count+1,resize=False)"
      ],
      "metadata": {
        "id": "m0CDNUPC912f"
      },
      "execution_count": 1107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Add race data to new qualifying results\n",
        "\n",
        "qualifying_women.insert(0, \"Units\", racedist_units)\n",
        "qualifying_women.insert(0, \"Distance\", racedist)\n",
        "qualifying_women.insert(0, \"Date\", racedate)\n",
        "qualifying_women.insert(0, \"Race\", racefile_name.replace(\"_\", \" \"))\n",
        "\n",
        "qualifying_men.insert(0, \"Units\", racedist_units)\n",
        "qualifying_men.insert(0, \"Distance\", racedist)\n",
        "qualifying_men.insert(0, \"Date\", racedate)\n",
        "qualifying_men.insert(0, \"Race\", racefile_name.replace(\"_\", \" \"))\n",
        "\n",
        "qualifying_nonbinary.insert(0, \"Units\", racedist_units)\n",
        "qualifying_nonbinary.insert(0, \"Distance\", racedist)\n",
        "qualifying_nonbinary.insert(0, \"Date\", racedate)\n",
        "qualifying_nonbinary.insert(0, \"Race\", racefile_name.replace(\"_\", \" \"))"
      ],
      "metadata": {
        "id": "gNrqyic6o8sS"
      },
      "execution_count": 1108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Append new qualifiers to the summary (with dates)\n",
        "\n",
        "summary_data = sum_worksheet.get_all_values()\n",
        "\n",
        "separator_row = ['****', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
        "chunks = (list(g) for k,g in groupby(summary_data, key=lambda x: x != separator_row) if k)\n",
        "\n",
        "leftover_chunks = []\n",
        "\n",
        "for chunk in chunks:\n",
        "  if chunk[0][0] == \"Qualifying Women\":\n",
        "    qualifying_women_summary = chunk\n",
        "  elif chunk[0][0] == \"Qualifying Men\":\n",
        "    qualifying_men_summary = chunk\n",
        "  elif chunk[0][0] == \"Qualifying Nonbinary\":\n",
        "    qualifying_nonbinary_summary = chunk\n",
        "  else:\n",
        "    leftover_chunks += chunk  \n",
        "\n",
        "## Build data frames from existing lists. This is probably unnecessary but I need\n",
        "## to think through how to handle more stuff being added to the spreadsheet\n",
        "\n",
        "qualifying_women_summary_df = pd.DataFrame(qualifying_women_summary)\n",
        "qualifying_women_summary_df.columns = qualifying_women_summary_df.iloc[1]\n",
        "qualifying_women_summary_df = qualifying_women_summary_df.iloc[2:]\n",
        "qualifying_women_summary_df = qualifying_women_summary_df[qualifying_women_summary_df['Name'].str.strip().astype(bool)]\n",
        "\n",
        "qualifying_men_summary_df = pd.DataFrame(qualifying_men_summary)\n",
        "qualifying_men_summary_df.columns = qualifying_men_summary_df.iloc[1]\n",
        "qualifying_men_summary_df = qualifying_men_summary_df.iloc[2:]\n",
        "qualifying_men_summary_df = qualifying_men_summary_df[qualifying_men_summary_df['Name'].str.strip().astype(bool)]\n",
        "\n",
        "qualifying_nonbinary_summary_df = pd.DataFrame(qualifying_nonbinary_summary)\n",
        "qualifying_nonbinary_summary_df.columns = qualifying_nonbinary_summary_df.iloc[1]\n",
        "qualifying_nonbinary_summary_df = qualifying_nonbinary_summary_df.iloc[2:]\n",
        "qualifying_nonbinary_summary_df = qualifying_nonbinary_summary_df[qualifying_nonbinary_summary_df['Name'].str.strip().astype(bool)]\n",
        "\n",
        "## Append new qualifiers\n",
        "\n",
        "qualifying_women_summary_df = pd.concat([qualifying_women_summary_df, qualifying_women], ignore_index=True)\n",
        "qualifying_women_summary_df[\"Date\"] = pd.to_datetime(qualifying_women_summary_df[\"Date\"], format = '%Y-%m-%d')\n",
        "qualifying_women_summary_df = qualifying_women_summary_df.dropna(subset = [\"Date\"]).sort_values(\"Date\")\\\n",
        "                              .drop_duplicates(\"Name\",keep=\"last\")\n",
        "\n",
        "qualifying_men_summary_df = pd.concat([qualifying_men_summary_df, qualifying_men], ignore_index=True)\n",
        "qualifying_men_summary_df[\"Date\"] = pd.to_datetime(qualifying_men_summary_df[\"Date\"], format = '%Y-%m-%d')\n",
        "qualifying_men_summary_df = qualifying_men_summary_df.dropna(subset = [\"Date\"]).sort_values(\"Date\")\\\n",
        "                            .drop_duplicates(\"Name\",keep=\"last\")\n",
        "\n",
        "qualifying_nonbinary_summary_df = pd.concat([qualifying_nonbinary_summary_df, qualifying_nonbinary], ignore_index=True)\n",
        "qualifying_nonbinary_summary_df[\"Date\"] = pd.to_datetime(qualifying_nonbinary_summary_df[\"Date\"], format = '%Y-%m-%d')\n",
        "qualifying_nonbinary_summary_df = qualifying_nonbinary_summary_df.dropna(subset = [\"Date\"]).sort_values(\"Date\")\\\n",
        "                                  .drop_duplicates(\"Name\",keep=\"last\")\n"
      ],
      "metadata": {
        "id": "qaba55ySGKK_"
      },
      "execution_count": 1109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Rewrite the summary Google sheet with the new qualifiers appended\n",
        "\n",
        "ws = wb.worksheet(\"Summary\")\n",
        "ws.clear()\n",
        "ws.delete_rows(1, ws.row_count)\n",
        "\n",
        "## Women list\n",
        "\n",
        "ws = wb.worksheet(\"Summary\")\n",
        "ws.add_rows(2)\n",
        "ws.update_cell(ws.row_count+1, 1, '****')\n",
        "ws.update_cell(ws.row_count+2, 1, 'Qualifying Women')\n",
        "\n",
        "ws = wb.worksheet(\"Summary\")\n",
        "ws.add_rows(qualifying_women_summary_df.shape[0]+2)\n",
        "gd.set_with_dataframe(worksheet=ws,dataframe=qualifying_women_summary_df,include_index=False,include_column_header=True,row=ws.row_count+1,resize=False)\n",
        "\n",
        "## Men list\n",
        "\n",
        "ws = wb.worksheet(\"Summary\")\n",
        "ws.add_rows(2)\n",
        "ws.update_cell(ws.row_count+1, 1, '****')\n",
        "ws.update_cell(ws.row_count+2, 1, 'Qualifying Men')\n",
        "\n",
        "ws = wb.worksheet(\"Summary\")\n",
        "ws.add_rows(qualifying_men_summary_df.shape[0]+2)\n",
        "gd.set_with_dataframe(worksheet=ws,dataframe=qualifying_men_summary_df,include_index=False,include_column_header=True,row=ws.row_count+1,resize=False)\n",
        "\n",
        "## Nonbinary list\n",
        "\n",
        "ws = wb.worksheet(\"Summary\")\n",
        "ws.add_rows(2)\n",
        "ws.update_cell(ws.row_count+1, 1, '****')\n",
        "ws.update_cell(ws.row_count+2, 1, 'Qualifying Nonbinary')\n",
        "\n",
        "ws = wb.worksheet(\"Summary\")\n",
        "ws.add_rows(qualifying_nonbinary_summary_df.shape[0]+2)\n",
        "gd.set_with_dataframe(worksheet=ws,dataframe=qualifying_nonbinary_summary_df,include_index=False,include_column_header=True,row=ws.row_count+1,resize=False)\n",
        "\n",
        "## Anything below the final **** (or strictly, anything in any other chunk will be re-appended here)\n",
        "\n",
        "ws.add_rows(2)\n",
        "ws.update_cell(ws.row_count+2, 1, '****')\n",
        "wb.values_append(\"Summary\", {'valueInputOption': 'USER_ENTERED'}, {'values': leftover_chunks})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVB10VC-Way1",
        "outputId": "c696f10f-c93c-43c7-8153-93497dd4ca72"
      },
      "execution_count": 1110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1n_xmaQuNmj3JBfOXJEN8c4HZAOUPOjtPAM-fY4h4K54',\n",
              " 'tableRange': 'Summary!A2:Q48',\n",
              " 'updates': {'spreadsheetId': '1n_xmaQuNmj3JBfOXJEN8c4HZAOUPOjtPAM-fY4h4K54',\n",
              "  'updatedRange': 'Summary!A49:Q85',\n",
              "  'updatedRows': 37,\n",
              "  'updatedColumns': 17,\n",
              "  'updatedCells': 629}}"
            ]
          },
          "metadata": {},
          "execution_count": 1110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Add race data to new total results\n",
        "\n",
        "racedata.insert(0, \"Units\", racedist_units)\n",
        "racedata.insert(0, \"Distance\", racedist)\n",
        "racedata.insert(0, \"Date\", racedate)\n",
        "racedata.insert(0, \"Race\", racefile_name.replace(\"_\", \" \"))"
      ],
      "metadata": {
        "id": "X85zjkDOzBXO"
      },
      "execution_count": 1111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This is the spreadsheet containing the entire active team\n",
        "team = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1-lUNQiVyxfwjEiuv1kiZSeMRUKGX-EtUSJPHucyOIaw/edit#gid=0\")\n",
        "\n",
        "## This is the worksheet containing best paces\n",
        "best_pace = team.worksheet(\"Best Pace\").get_all_values()\n",
        "best_pace_df = pd.DataFrame(best_pace)\n",
        "best_pace_df.columns = best_pace_df.iloc[0]\n",
        "best_pace_df = best_pace_df.iloc[1:]\n",
        "best_pace_df = best_pace_df.dropna(subset=[\"Name\"])\n",
        "\n",
        "## This is the worksheet containing most recent races\n",
        "most_recent = team.worksheet(\"Most Recent\").get_all_values()\n",
        "most_recent_df = pd.DataFrame(most_recent)\n",
        "most_recent_df.columns = most_recent_df.iloc[0]\n",
        "most_recent_df = most_recent_df.iloc[1:]\n",
        "most_recent_df = most_recent_df.dropna(subset=[\"Name\"])\n",
        "\n",
        "## This is the worksheet containing both\n",
        "all_data = team.worksheet(\"All\").get_all_values()\n",
        "all_data_df = pd.DataFrame(all_data)\n",
        "all_data_df.columns = all_data_df.iloc[0]\n",
        "all_data_df = all_data_df.iloc[1:]\n",
        "all_data_df = all_data_df.dropna(subset=[\"Name\"])\n",
        "\n",
        "## Put name at the front\n",
        "name_column = racedata.pop(\"Name\")\n",
        "racedata.insert(0, \"Name\", name_column)\n",
        "\n",
        "## If this is a points race, drop anything older than a year\n",
        "\n",
        "if pointsrace == True:\n",
        "  yearago = datetime.date.today() - datetime.timedelta(days=365.24)\n",
        "  most_recent_df = most_recent_df[~(most_recent_df[\"Date\"] < yearago)]\n",
        "  best_pace_df = best_pace_df[~(most_recent_df[\"Date\"] < yearago)]\n",
        "\n",
        "## Append\n",
        "\n",
        "most_recent_df = pd.concat([most_recent_df, racedata])\n",
        "best_pace_df = pd.concat([best_pace_df, racedata])\n",
        "\n",
        "## Drop duplicates by date and pace\n",
        "\n",
        "most_recent_df[\"Date\"] = pd.to_datetime(most_recent_df[\"Date\"], format = '%Y-%m-%d')\n",
        "best_pace_df[\"Date\"] = pd.to_datetime(best_pace_df[\"Date\"], format = '%Y-%m-%d')\n",
        "most_recent_df[\"BestPace_s\"] = pd.to_numeric(most_recent_df[\"BestPace_s\"])\n",
        "best_pace_df[\"BestPace_s\"] = pd.to_numeric(best_pace_df[\"BestPace_s\"])\n",
        "\n",
        "most_recent_df = most_recent_df.dropna(subset=[\"Date\"]).sort_values(\"Date\")\\\n",
        "                .drop_duplicates(\"Name\",keep=\"last\")\n",
        "most_recent_df = most_recent_df.dropna(subset=[\"Date\"]).sort_values(\"BestPace_s\")\\\n",
        "\n",
        "best_pace_df = best_pace_df.dropna().sort_values(\"BestPace_s\")\\\n",
        "               .drop_duplicates(\"Name\",keep=\"first\")\n",
        "\n",
        "## Create combined list\n",
        "\n",
        "all_data_df = most_recent_df.add_prefix('Recent_')\\\n",
        "              .merge(best_pace_df.add_prefix('BestRace_'), left_on=\"Recent_Name\",\\\n",
        "                    right_on=\"BestRace_Name\", how=\"left\")\n",
        "              \n",
        "all_data_df = all_data_df.rename(columns={\"Recent_Name\": \"Name\"})\n",
        "all_data_df = all_data_df.drop(columns=\"BestRace_Name\")\n",
        "current_corral = all_data_df[\"BestRace_Corral\"]\n",
        "current_bestpace = all_data_df[\"BestRace_BestPace\"]\n",
        "all_data_df.insert(1, \"Corral\", current_corral)\n",
        "all_data_df.insert(2, \"Best Pace\", current_bestpace)"
      ],
      "metadata": {
        "id": "83KqNmQpvn1r"
      },
      "execution_count": 1112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Write active team spreadsheet\n",
        "\n",
        "ws = team.worksheet(\"Most Recent\")\n",
        "ws.clear()\n",
        "gd.set_with_dataframe(worksheet=ws,dataframe=most_recent_df,include_index=False,include_column_header=True,row=1,resize=False)\n",
        "\n",
        "ws = team.worksheet(\"Best Pace\")\n",
        "ws.clear()\n",
        "gd.set_with_dataframe(worksheet=ws,dataframe=best_pace_df,include_index=False,include_column_header=True,row=1,resize=False)\n",
        "\n",
        "ws = team.worksheet(\"All\")\n",
        "ws.clear()\n",
        "gd.set_with_dataframe(worksheet=ws,dataframe=all_data_df,include_index=False,include_column_header=True,row=1,resize=False)\n"
      ],
      "metadata": {
        "id": "PT_lO0hn5xA9"
      },
      "execution_count": 1113,
      "outputs": []
    }
  ]
}